<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Project Template</title>
  <style>
    :root {
      --primary-color: #004e89;
      --secondary-color: #f7f0ff;
      --accent-color: #e0f0ff;
      --font-sans: 'Segoe UI', sans-serif;
    }
    /* Reset */
    * { margin: 0; padding: 0; box-sizing: border-box; }
    html { scroll-behavior: smooth; }
    body { font-family: var(--font-sans); background: var(--secondary-color); color: #333; }
    a { text-decoration: none; color: inherit; }
    ul { list-style: none; padding-left: 1.5rem; }
    p { margin: 1rem 0; text-align: justify; }

    /* Header & Navigation */
    header {
      background: var(--primary-color);
      color: #fff;
      position: sticky;
      top: 0;
      width: 100%;
      box-shadow: 0 2px 8px rgba(0,0,0,0.1);
      z-index: 1000;
    }
    .nav-container {
      max-width: 1200px;
      margin: 0 auto;
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 1rem;
    }
    .logo {
      font-size: 1.5rem;
      font-weight: bold;
    }
    nav ul {
      display: flex;
      gap: 1rem;
    }
    .menu-icon {
      display: none;
      flex-direction: column;
      cursor: pointer;
    }
    .menu-icon span,
    .menu-icon span::before,
    .menu-icon span::after {
      content: '';
      display: block;
      height: 3px;
      background: #fff;
      margin: 5px 0;
      transition: 0.3s;
    }
    #menu-toggle { display: none; }
    @media (max-width: 768px) {
      .menu-icon { display: flex; }
      nav ul {
        position: absolute;
        top: 100%; left: 0;
        width: 100%;
        flex-direction: column;
        background: var(--primary-color);
        max-height: 0;
        overflow: hidden;
        transition: max-height 0.3s ease;
      }
      #menu-toggle:checked + .menu-icon + nav ul {
        max-height: 300px;
      }
      nav li { text-align: center; padding: 1rem 0; }
    }

    /* Sections & Animations */
    section {
      padding: 4rem 1rem;
      opacity: 0;
      transform: translateY(20px);
      transition: opacity 0.6s ease-out, transform 0.6s ease-out;
    }
    section.visible {
      opacity: 1;
      transform: translateY(0);
    }
    .container { max-width: 1200px; margin: 0 auto; }
    .section-title {
      font-size: 2rem;
      color: var(--primary-color);
      margin-bottom: 1.5rem;
      border-bottom: 2px solid var(--accent-color);
      padding-bottom: 0.5rem;
    }
    h3 {
      font-size: 1.5rem;
      margin-top: 1.5rem;
      color: var(--primary-color);
    }
    .code-block {
      background: #f1f1f1;
      padding: 1rem;
      border-radius: 8px;
      overflow-x: auto;
      font-family: monospace;
      margin: 1rem 0;
      white-space: pre;
    }
    /* Demo Video Sizing */
    .video-grid {
      display: flex;
      flex-wrap: wrap;
      gap: 1rem;
      justify-content: center;
    }
    .video-grid video {
      width: 100%;
      max-width: 320px;
      height: auto;
      border-radius: 8px;
    }

    /* Footer */
    footer {
      background: var(--primary-color);
      color: #fff;
      text-align: center;
      padding: 2rem 1rem;
    }
  </style>
</head>
<body>
  <header>
    <div class="nav-container">
      <div class="logo">Automated Vacuum Cleaner</div>
      <input type="checkbox" id="menu-toggle" />
      <label for="menu-toggle" class="menu-icon"><span></span></label>
      <nav>
        <ul>
          <li><a href="#team">Team</a></li>
          <li><a href="#overview">Overview</a></li>
          <li><a href="#literature-review">Literature Review</a></li>
          <li><a href="#methodology">Methodology</a></li>
          <li><a href="#hardware">Hardware</a></li>
          <li><a href="#software">Software</a></li>
          <li><a href="#arduino">Arduino</a></li>
          <li><a href="#demo">Demo</a></li>
          <li><a href="#conclusion">Conclusion</a></li>
          <li><a href="#references">References</a></li>
        </ul>
      </nav>
    </div>
  </header>

  <main>
    <section id="team">
      <div class="container">
        <h2 class="section-title">Team B1 Members</h2>
        <ul>
          <li>Yeturu Hemesh : CB.SC.U4AIE23166</li>
          <li>Joel John : CB.SC.U4AIE23131</li>
          <li>Abhishek Sankaramani : CB.SC.U4AIE23107</li>
          <li>Adarsh P : CB.SC.U4AIE23109</li>
        </ul>
      </div>
    </section>

    <section id="overview">
      <div class="container">
        <h2 class="section-title">Project Overview</h2>
        <!-- Overview content -->
        <p>
          The project is about developing an Automated Vacuum Cleaner Robot that combines advanced robotics and mathematics for efficient autonomous cleaning. The robot uses Fourier and Discrete Cosine Transforms (DCT) for image processing, enabling it to distinguish between dust and obstacles. ADMM is applied for image denoising, while compressed sensing helps reduce the number of samples needed for image processing, saving computational resources.<br><br>
          Machine learning (logistic regression) is employed for obstacle classification, and Stochastic Gradient Descent is used to train the model. The vacuum's navigation relies on the A* algorithm for path planning and graph Laplacians for complete area coverage. Future enhancements could involve deep learning for object recognition, SLAM for environmental mapping, and reinforcement learning for adaptive cleaning strategies.
        </p>
      </div>
    </section>

    <section id="literature-review">
      <div class="container">
        <h2 class="section-title">Literature Review</h2>
        <!-- Literature Review content -->
        <table>
          <thead>
            <tr>
              <th>Phase</th>
              <th>Representative Works</th>
              <th>Main Contributions</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>2000–2010<br>Early Developments</td>
              <td>
                • iRobot Roomba (2002)<br>
                • Thrun et al. (2005) Probabilistic SLAM
              </td>
              <td>
                • First commercial random-coverage cleaning robot<br>
                • Introduction of probabilistic SLAM for indoor mapping
              </td>
            </tr>
            <tr>
              <td>2010–2015<br>Mapping &amp; Navigation Enhancements</td>
              <td>
                • Wang et al. (2012) Grid-based SLAM<br>
                • Huang et al. (2013) Topological SLAM<br>
                • Kim (2014) Differential-drive + PID control
              </td>
              <td>
                • Structured environment representation<br>
                • Improved real-time control via ultrasonic feedback
              </td>
            </tr>
            <tr>
              <td>2015–2020<br>Integration of AI &amp; Vision</td>
              <td>
                • Furukawa et al. (2016) Monocular/depth vision<br>
                • Ma et al. (2017) CNN-based dirt detection<br>
                • Xiaomi/Neato consumer models (LiDAR + VIO)
              </td>
              <td>
                • Vision-based obstacle detection for robust navigation<br>
                • Selective cleaning via deep learning<br>
                • Real-time localization with LiDAR &amp; visual-inertial odometry
              </td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>

    <section id="methodology">
      <div class="container">
        <h2 class="section-title">Methodology</h2>
        <!-- Methodology content -->
        <h3>1. Image Preprocessing &amp; Feature Extraction</h3>
        <p>Captured images are converted to the frequency domain to highlight key features:</p>
        <div class="code-block">
F(u) = ∫ f(x)e<sup>-j2πux</sup>dx
<br>
C(u,v) = α(u)α(v) ∑<sub>x,y</sub> f(x,y) cos(...)cos(...)
        </div>

        <h3>2. Image Denoising using ADMM</h3>
        <p>We solve an L<sub>1</sub>-regularized optimization for noise removal:</p>
        <div class="code-block">
min<sub>x,z</sub> (½‖x–b‖² + λ‖z‖<sub>1</sub>)
<br>
L<sub>ρ</sub>(x,z,u) = ½‖x–b‖² + λ‖z‖<sub>1</sub> + uᵀ(Dx–z) + (ρ/2)‖Dx–z‖²
        </div>

        <h3>3. Compressed Sensing</h3>
        <p>Reduce measurements while preserving features:</p>
        <div class="code-block">
y = Φx = ΦΨα
<br>
min‖α‖<sub>1</sub> s.t. y = ΦΨα
        </div>

        <h3>4. Object Classification with Logistic Regression</h3>
        <p>Binary model to distinguish dust vs. obstacles:</p>
        <div class="code-block">
P(y=1|x)=1/(1+e<sup>-θᵀx</sup>)
<br>
J(θ)=–(1/m)∑[y logσ(θᵀx)+(1–y)log(1–σ(θᵀx))]
        </div>

        <h3>5. Path Planning using A* Algorithm</h3>
        <p>Compute shortest path with heuristic guidance:</p>
        <div class="code-block">
f(n)=g(n)+h(n)
<br>
h(n)=|x<sub>goal</sub>–x|+|y<sub>goal</sub>–y|
        </div>

        <h3>6. Graph Laplacians for Area Coverage</h3>
        <p>Spectral methods to plan sweeping routes:</p>
        <div class="code-block">
L=D–A
        </div>

        <h3>7. Embedded Control &amp; Implementation</h3>
        <p>Differential-drive kinematics with PID:</p>
        <div class="code-block">
v=(R/2)(ω<sub>R</sub>+ω<sub>L</sub>)
<br>
w=(R/B)(ω<sub>R</sub>–ω<sub>L</sub>)
        </div>

      </div>
    </section>

    <section id="hardware">
      <div class="container">
        <h2 class="section-title">Hardware Architecture</h2>
        <!-- Hardware content -->
        <ul>
          <li class="hardware-item">Arduino Uno</li>
          <li class="hardware-item">ESP32-CAM</li>
          <li class="hardware-item">Ultrasonic Sensor on Servo</li>
          <li class="hardware-item">Motor Shield</li>
          <li class="hardware-item">DC Motors and Wheels</li>
          <li class="hardware-item">Battery Pack 12V </li>
        </ul>
      </div>
    </section>

    <section id="software">
      <div class="container">
        <h2 class="section-title">Software Architecture</h2>
        <!-- Software content -->
        <p> Module Breakdown
          <br> Image Processing Module (PC Side)
          The ESP32-CAM streams live video to the PC, where Python captures the feed and processes it. The image is converted to grayscale and denoised using ADMM with DCT. The processed image is resized to 64x64 and flattened into a feature vector for classification. </br>
          
          <br> Logistic Regression Classification Module (PC Side) </br>
          <br> The logistic regression model is trained using labeled dust and obstacle images. The model is stored in a .pkl file and used for real-time classification. It outputs commands (either move forward or avoid) based on the classification result. </br>
          
          <br> Motor Control and Command Communication (PC & Arduino) </br>
          <br> The PC sends movement commands ('F' for forward, 'A' for avoid) via serial communication to the Arduino. The Arduino interprets these commands and controls the motors using a Motor Driver (L298N). The Arduino adjusts robot movement based on sensor inputs. </br>
          
          <br> Obstacle Detection and Navigation </br>
          <br> The Ultrasonic Sensor and Servo Motor detect obstacles and scan the environment in real-time. Python constructs a grid map, marking obstacles and determining the robot's path. The A* algorithm calculates the optimal route while avoiding obstacles. </br>
          
          <br> Path Planning Module </br>
          <br> A grid map is maintained in Python, and the A* algorithm computes the best path to the target. The robot continuously updates the grid map with new obstacles detected by the Ultrasonic Sensor and ESP32-CAM. If new obstacles are found, the robot recalculates its path. </br>
          
          <br> Communication and Power </br>
          <br> The ESP32-CAM streams video to the PC via Wi-Fi. Serial communication (9600 baud) is used between the PC and Arduino for motor commands and sensor data exchange. Power is supplied via a USB or battery pack to both ESP32-CAM and Arduino. </br> .</p>
              <div class="code">
          <pre>
          +--------------------------------------+
          |            Smart Vacuum             |
          |          Cleaner Robot System        |
          +--------------------------------------+
          |                                      |
          |   +----------------------------+     |
          |   |      Image Processing       |     |<----(Wi-Fi)---> ESP32-CAM
          |   |       (PC Side)             |     |
          |   | - Video Capture (OpenCV)    |     |
          |   | - ADMM Denoising (Python)   |     |
          |   | - Feature Extraction        |     |
          |   | - Logistic Regression       |     |
          |   +----------------------------+     |
          |                                      |
          |   +----------------------------+     |
          |   |   Obstacle Detection &      |     |
          |   |   Path Planning (Python)    |     |
          |   | - A* Pathfinding            |     |
          |   | - Grid Mapping              |     |
          |   | - Obstacle Update           |     |
          |   +----------------------------+     |
          |                                      |
          |   +----------------------------+     |
          |   |    Motor & Sensor Control   |     |
          |   |   (Arduino Uno)             |     |
          |   | - Serial Communication      |     |
          |   | - Motor Control (L298N)     |     |
          |   | - Ultrasonic Sensor Control |     |
          |   +----------------------------+     |
          |                                      |
          +--------------------------------------+</pre>
              </div>
      </div>
    </section>

    <section id="arduino">
      <div class="container">
        <h2 class="section-title">Arduino Integration</h2>
        <p>The Arduino Uno handles low-level motor and sensor control, interfacing with the PC for navigation commands.</p>
        <ul>
          <li><strong>Motor &amp; Sensor Control:</strong> Drives DC motors via L298N driver and reads ultrasonic sensor data to detect obstacles.</li>
          <li><strong>Serial Communication (9600 baud):</strong> Receives 'F' (forward) and 'A' (avoid) commands from the PC, sending real-time feedback.</li>
          <li><strong>Control Logic:</strong>
            <ul>
              <li><em>'F':</em> Both motors spin forward.</li>
              <li><em>'A':</em> Robot reverses then turns to avoid obstacle.</li>
            </ul>
          </li>
          <li><strong>Servo-mounted Ultrasonic Sensor:</strong> Rotates to scan environment; Arduino filters distance readings for reliable detection.</li>
          <li><strong>Real-time Feedback Loop:</strong> Continuously updates motor actions based on path planner and obstacle data.</li>
        </ul>
        <div class="code-block">
+------------------------------------------------------------+
|                         Arduino Uno                        |
| +---------------+    +------------------------------------+|
| | L298N Driver  |----| DC Motors (Wheels)                ||
| +---------------+    +------------------------------------+|
|                                                            |
| +------------+   +----------------------------------------+|
| | Ultrasonic |---| Ultrasonic Sensor (Distance Measure)   ||
| | Sensor     |   +----------------------------------------+|
| +------------+                                      +----+|
|                                                   |Servo| |
|                                                   |Motor| |
|                                                   +----+ |
|                                                            |
| Serial (USB, 9600 baud)                                  |
+------------------------------------------------------------+
        </div>
      </div>
    </section>

    <section id="demo">
      <div class="container">
        <h2 class="section-title">Demo</h2>
        <!-- Demo content -->
        <p>This section showcases our robot’s simulation environments and hardware demonstrations.</p>
  
        <h3>Simulation Videos</h3>
        <div class="video-grid">
          <video controls>
            <source src="ads.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video controls>
            <source src="ads1.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video controls>
            <source src="ads2.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      
        <h3>Hardware Setup Image</h3>
        <img class="demo-image" src="hardware.png" alt="Smart Vacuum Cleaner Hardware">
      
        <h3>Hardware Demo Videos</h3>
        <div class="video-grid">
          <video controls>
            <source src="1.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video controls>
            <source src="2.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
      </div>
    </section>

    <section id="conclusion">
      <div class="container">
        <h2 class="section-title">Conclusion</h2>
        <!-- Conclusion content -->
        <p>This project successfully demonstrates the design and implementation of a cost-effective Autonomous Vacuum Cleaner Robot that integrates vision-based perception, mathematical modeling, and efficient path planning. By utilizing a single camera combined with Fourier and DCT-based image analysis, the system accurately detects and distinguishes between floor textures, dust particles, and obstacles. Advanced optimization techniques like ADMM and compressed sensing significantly enhance noise reduction and image clarity for improved feature extraction.</p>
        <p>Machine learning models, particularly logistic regression, enable real-time classification of obstacles, while A* and Dijkstra’s algorithms ensure optimal route computation for complete area coverage. The system operates reliably using differential drive kinematics controlled via PID, and the entire functionality is realized on low-cost embedded hardware platforms like Arduino and Raspberry Pi.</p>
      
      </div>
    </section>

    <section id="references">
      <div class="container">
        <h2 class="section-title">References</h2>
        <!-- References content -->
        <ol>
          <li>Burgard, W., Fox, D., &amp; Thrun, S. (1997). Active mobile robot localization. <em>Robotics</em>, pp. 1346–1352.</li>
          <li>Burgard, W., Bennewitz, M., &amp; Stachniss, C. (2017). Learning spatial representations for efficient robot navigation. <em>Robotics and Autonomous Systems</em>, 87, 162–176.</li>
          <li>Jähne, B., &amp; Haussecker, H. (2018). Advancements in machine vision for robotic inspection and measurement. <em>Machine Vision and Applications</em>, 29(5), 789–809.</li>
          <li>Demiris, Y., &amp; Schiele, B. (2019). Development of vision-based artificial agents for autonomous interaction. <em>IEEE Transactions on Robotics</em>, 35(3), 617–634.</li>
          <li>LaValle, S. M. (2020). Modern approaches to robot motion planning. In <em>Springer Tracts in Advanced Robotics</em> (Vol. 123). Springer.</li>
          <li>Xu, Z., Zhan, X., Xiu, Y., Suzuki, C., &amp; Shimada, K. (2023). Onboard dynamic-object detection and tracking for autonomous robot navigation with RGB-D camera. <em>IEEE Robotics and Automation Letters</em>.</li>
        </ol>
      </div>
    </section>
  </main>

  <footer>
    <div class="container">
      &copy; 2025 Team B1
    </div>
  </footer>
  <script>
    // Scroll reveal animation
    document.addEventListener('DOMContentLoaded', () => {
      const sections = document.querySelectorAll('section');
      const observer = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            entry.target.classList.add('visible');
          }
        });
      }, { threshold: 0.2 });
      sections.forEach(sec => observer.observe(sec));
    });
  </script>
</body>
</html>
